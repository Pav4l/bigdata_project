import scrapy
import datetime
from myparser.items import MyparserItem


class MySpider(scrapy.Spider):
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—É–∫ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–∞ books.toscrape.com."""
    name = "my_spider"
    allowed_domains = ["books.toscrape.com"]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö URL ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞
    start_urls = [
        f"http://books.toscrape.com/catalogue/page-{i}.html" for i in range(1, 6)
    ]

    def parse(self, response):
        """–ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é."""
        for href in response.css("h3 a::attr(href)").getall():
            yield response.follow(
                href,
                callback=self.parse_product,
                # meta={"use_selenium": True}  # üëà middleware –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç —ç—Ç–æ
            )

        # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
        next_page = response.css("li.next a::attr(href)").get()
        if next_page:
            yield response.follow(next_page, callback=self.parse)

    def parse_product(self, response):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞."""
        item = MyparserItem()
        item["url"] = response.url
        item["parse_time"] = datetime.datetime.utcnow()
        item["title"] = response.css("div.product_main h1::text").get()
        item["description"] = " ".join(
            response.css("#product_description ~ p::text").getall()
        ).strip()

        price_text = response.css("p.price_color::text").re_first(r"[\d\.,]+")
        item["price"] = float(price_text.replace(",", ".")) if price_text else None

        # –ü—Ä–∏–º–µ—Ä –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–Ω–∞ —Å–∞–π—Ç–µ –∏—Ö –Ω–µ—Ç, –æ—Å—Ç–∞–≤–ª—è–µ–º —à–∞–±–ª–æ–Ω)
        item["attributes"] = {
            "availability": response.css("p.availability::text").re_first(r"\w+")
        }

        item["comments"] = [
            {"text": c.get()}
            for c in response.css(".comment::text")
        ]

        item["links"] = response.css("a::attr(href)").getall()

        yield item
